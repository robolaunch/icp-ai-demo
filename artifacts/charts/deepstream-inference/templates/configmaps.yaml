apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ include "deepstream-inference.fullname" . }}-deepstream
  labels:
  {{- include "deepstream-inference.labels" . | nindent 4 }}
data:
  init.sh: |
    #!/bin/bash
    
    {{ if eq .Values.inference.model.format "pt" }}

    {{ if eq .Values.inference.model.framework "YOLOV7" }}
    # apply if converted from YOLOV7
    cd /opt/nvidia/deepstream/deepstream-6.4/yolov7
    cp ../DeepStream-Yolo/utils/export_yoloV7.py .
    wget {{ .Values.inference.model.url }}
    mv {{ .Values.inference.model.filename }} main_model.pt
    python3 export_yoloV7.py -w main_model.pt --dynamic
    {{ end }}

    {{ if eq .Values.inference.model.framework "YOLOV8" }}
    # apply if converted from YOLOV8
    cd /opt/nvidia/deepstream/deepstream-6.4/yolov7
    cp ../DeepStream-Yolo/utils/export_yoloV8.py .
    wget {{ .Values.inference.model.url }}
    mv {{ .Values.inference.model.filename }} main_model.pt
    python3 export_yoloV8.py -w main_model.pt --dynamic
    {{ end }}

    cp labels.txt ../DeepStream-Yolo
    cp main_model.onnx ../DeepStream-Yolo
    cd /opt/nvidia/deepstream/deepstream-6.4/sources/apps/sample_apps/deepstream-test5
    
    # move artifacts from DeepStream-YOLO repository to deepstream-test5
    # cp /opt/nvidia/deepstream/deepstream-6.4/DeepStream-Yolo/config_infer_primary_yoloV7.txt .
    cp /opt/nvidia/deepstream/deepstream-6.4/DeepStream-Yolo/labels.txt .
    cp /opt/nvidia/deepstream/deepstream-6.4/DeepStream-Yolo/main_model.onnx .
    cp -r /opt/nvidia/deepstream/deepstream-6.4/DeepStream-Yolo/nvdsinfer_custom_impl_Yolo/ .

    {{ end }}
    
    # copy config
    cd /opt/nvidia/deepstream/deepstream-6.4/sources/apps/sample_apps/deepstream-test5/
    cp config/inference_config.txt configs/inference_config.txt 

    echo -n \"--------------FINISHED--------------\"
  dstest5_msgconv_sample_config.txt: |
    [sensor0]
    enable=1
    type=Camera
    id=HWY_20_AND_LOCUST__EBA__4_11_2018_4_59_59_508_AM_UTC-07_00
    location=45.293701447;-75.8303914499;48.1557479338
    description=Aisle Camera
    coordinate=5.2;10.1;11.2

    [sensor1]
    enable=1
    type=Camera
    id=HWY_20_AND_LOCUST__WBA__4_11_2018_4_59_59_379_AM_UTC-07_00
    location=45.293701447;-75.8303914499;48.1557479338
    description=Aisle Camera
    coordinate=5.2;10.1;11.2

    [sensor2]
    enable=1
    type=Camera
    id=HWY_20_AND_DEVON__WBA__4_11_2018_4_59_59_134_AM_UTC-07_00
    location=45.293701447;-75.8303914499;48.1557479338
    description=Aisle Camera
    coordinate=5.2;10.1;11.2

    [sensor3]
    enable=1
    type=Camera
    id=HWY_20_AND_LOCUST__4_11_2018_4_59_59_320_AM_UTC-07_00
    location=45.293701447;-75.8303914499;48.1557479338
    description=Aisle Camera
    coordinate=5.2;10.1;11.2

    [place0]
    enable=1
    id=0
    type=intersection/road
    name=HWY_20_AND_LOCUST__EBA
    location=30.32;-40.55;100.0
    coordinate=1.0;2.0;3.0
    place-sub-field1=C_127_158
    place-sub-field2=Lane 1
    place-sub-field3=P1

    [place1]
    enable=1
    id=1
    type=intersection/road
    name=HWY_20_AND_LOCUST__WBA
    location=30.32;-40.55;100.0
    coordinate=1.0;2.0;3.0
    place-sub-field1=C_127_158
    place-sub-field2=Lane 1
    place-sub-field3=P1

    [place2]
    enable=1
    id=2
    type=intersection/road
    name=HWY_20_AND_DEVON__WBA
    location=30.32;-40.55;100.0
    coordinate=1.0;2.0;3.0
    place-sub-field1=C_127_158
    place-sub-field2=Lane 1
    place-sub-field3=P1

    [place3]
    enable=1
    id=3
    type=intersection/road
    name=HWY_20_AND_LOCUST
    location=30.32;-40.55;100.0
    coordinate=1.0;2.0;3.0
    place-sub-field1=C_127_158
    place-sub-field2=Lane 1
    place-sub-field3=P1

    [analytics0]
    enable=1
    id=XYZ_1
    description=Vehicle Detection and License Plate Recognition
    source=OpenALR
    version=1.0

    [analytics1]
    enable=1
    id=XYZ_2
    description=Vehicle Detection and License Plate Recognition 1
    source=OpenALR
    version=1.0

    [analytics2]
    enable=1
    id=XYZ_3
    description=Vehicle Detection and License Plate Recognition 2
    source=OpenALR
    version=1.0

    [analytics3]
    enable=1
    id=XYZ_4
    description=Vehicle Detection and License Plate Recognition 4
    source=OpenALR
    version=1.0
  deepstream_config.txt: |
    [application]
    enable-perf-measurement=1
    perf-measurement-interval-sec=5
    #gie-kitti-output-dir=streamscl

    [tiled-display]
    enable=1
    rows=1
    columns=1
    width={{ .Values.videoSink.width }}
    height={{ .Values.videoSink.height }}
    gpu-id=0
    nvbuf-memory-type=0

    [source0]
    enable=1
    type=4
    uri={{ .Values.rtspSourceURL }}
    num-sources=1
    gpu-id=0
    cudadec-memtype=0
    nvbuf-memory-type=0

    [sink0]
    enable=0
    #Type - 1=FakeSink 2=EglSink 3=File
    type=3
    sync=1
    source-id=0
    container=1
    codec=2
    output-file=/opt/nvidia/deepstream/deepstream-6.4/sources/apps/sample_apps/deepstream-test5/out.mp4
    gpu-id=0
    nvbuf-memory-type=0

    [sink1]
    enable=1
    source-id=0
    sync=1
    type=6
    msg-conv-config=dstest5_msgconv_sample_config.txt
    msg-conv-payload-type=1
    msg-conv-msg2p-new-api=0
    msg-conv-frame-interval=30
    msg-broker-proto-lib=/opt/nvidia/deepstream/deepstream/lib/libnvds_kafka_proto.so
    msg-broker-conn-str={{ .Values.videoSink.kafka.ip }};{{ .Values.videoSink.kafka.port }};{{ .Values.videoSink.kafka.topic }}
    topic={{ .Values.videoSink.kafka.topic }}

    {{ if (default .Values.videoSink.rtsp.enabled true) }}
    [sink2]
    enable=1
    type=4
    rtsp-port={{ .Values.videoSink.rtsp.port }}
    sync=0
    source-id=0
    codec=2
    bitrate=1000000
    {{ end }}

    {{ if (default .Values.boundingBoxes.enabled true) }}
    [osd]
    enable=1
    gpu-id=0
    border-width={{ .Values.boundingBoxes.borderWidth }}
    border-color={{ .Values.boundingBoxes.borderColor }}
    text-size={{ .Values.boundingBoxes.textSize }}
    text-color={{ .Values.boundingBoxes.textColor }}
    text-bg-color={{ .Values.boundingBoxes.textBackgroundColor }}
    font={{ .Values.boundingBoxes.font }}
    show-clock=0
    clock-x-offset=800
    clock-y-offset=820
    clock-text-size=12
    clock-color=1;0;0;0
    nvbuf-memory-type=0
    {{ end }}

    [streammux]
    gpu-id=0
    batch-size=1
    batched-push-timeout=40000
    width={{ .Values.videoSink.width }}
    height={{ .Values.videoSink.height }}
    enable-padding=0
    nvbuf-memory-type=0
    attach-sys-ts-as-ntp=1

    [primary-gie]
    enable=1
    gpu-id=0
    gie-unique-id=1
    nvbuf-memory-type=0
    config-file=/opt/nvidia/deepstream/deepstream-6.4/sources/apps/sample_apps/deepstream-test5/configs/inference_config.txt

    [tracker]
    enable=0
    tracker-width=960
    tracker-height=544
    ll-lib-file=/opt/nvidia/deepstream/deepstream/lib/libnvds_nvmultiobjecttracker.so
    ll-config-file=../../../../../samples/configs/deepstream-app/config_tracker_NvDCF_perf.yml
    gpu-id=0
    display-tracking-id=1

    [tests]
    file-loop=0
  inference_config.txt: |
    [property]
    gpu-id=0
    net-scale-factor=0.0039215697906911373
    model-color-format=0
    onnx-file=../main_model.onnx
    model-engine-file=../model_b1_gpu0_fp32.engine
    #int8-calib-file=calib.table
    labelfile-path=../labels.txt
    batch-size=1
    network-mode=0
    num-detected-classes=80
    interval=0
    gie-unique-id=1
    process-mode=1
    network-type=0
    cluster-mode=2
    maintain-aspect-ratio=1
    symmetric-padding=1
    #workspace-size=2000
    parse-bbox-func-name=NvDsInferParseYolo
    #parse-bbox-func-name=NvDsInferParseYoloCuda
    custom-lib-path=../nvdsinfer_custom_impl_Yolo/libnvdsinfer_custom_impl_Yolo.so
    engine-create-func-name=NvDsInferYoloCudaEngineGet

    [class-attrs-all]
    nms-iou-threshold=0.45
    pre-cluster-threshold=0.25
    topk=300